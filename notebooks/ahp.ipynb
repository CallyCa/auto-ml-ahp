{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa bibliotecas\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Time            V1            V2            V3            V4  \\\n",
      "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
      "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
      "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
      "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
      "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
      "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
      "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
      "\n",
      "                 V5            V6            V7            V8            V9  \\\n",
      "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
      "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
      "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
      "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
      "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
      "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
      "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
      "\n",
      "       ...           V21           V22           V23           V24  \\\n",
      "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
      "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
      "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
      "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
      "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
      "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
      "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
      "\n",
      "                V25           V26           V27           V28         Amount  \\\n",
      "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
      "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
      "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
      "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
      "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
      "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
      "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
      "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
      "\n",
      "               Class  \n",
      "count  284807.000000  \n",
      "mean        0.001727  \n",
      "std         0.041527  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n",
      "Resultados para o modelo SVM:\n",
      "Tempo de execução (s): 3.296463966369629\n",
      "Sensibilidade (%): 99.99859293654144\n",
      "Especificidade (%): 100.0\n",
      "Resultados para o modelo Random Forest:\n",
      "Tempo de execução (s): 65.48545169830322\n",
      "Sensibilidade (%): 100.0\n",
      "Especificidade (%): 100.0\n",
      "Resultados para o modelo KNN:\n",
      "Tempo de execução (s): 0.036043405532836914\n",
      "Sensibilidade (%): 100.0\n",
      "Especificidade (%): 100.0\n",
      "*** Resultados TOPSIS ***\n",
      "Modelo | Posição\n",
      "*** Resultados TOPSIS ***\n",
      "Modelo | Posição\n",
      "KNN | 1\n",
      "SVM | 2\n",
      "Random Forest | 3\n"
     ]
    }
   ],
   "source": [
    "# Leitura de dados\n",
    "df = pd.read_csv(\"../data/raw/creditcard.csv\")\n",
    "\n",
    "# Exploração de dados e pré-processamento\n",
    "print(df.describe())\n",
    "\n",
    "# Seleciona apenas variáveis numéricas\n",
    "df = df.select_dtypes(include=[\"int64\", \"float64\"])\n",
    "df.drop([\"Time\", \"Amount\"], axis=1, inplace=True)\n",
    "\n",
    "# Normaliza os dados\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Separação de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_scaled, df[\"Class\"], test_size=0.25, random_state=1512)\n",
    "\n",
    "# Oversampling e undersampling\n",
    "over = RandomOverSampler(sampling_strategy=\"auto\")\n",
    "under = RandomUnderSampler(sampling_strategy=\"auto\")\n",
    "\n",
    "# Use o índice para acessar o conjunto de dados resamplenado\n",
    "X_train_s = over.fit_resample(X_train, y_train)[0]\n",
    "y_train_s = over.fit_resample(X_train, y_train)[1]\n",
    "\n",
    "# Use o índice para acessar o conjunto de dados resamplenado novamente\n",
    "X_train_s = under.fit_resample(X_train_s, y_train_s)[0]\n",
    "y_train_s = under.fit_resample(X_train_s, y_train_s)[1]\n",
    "\n",
    "# Modelagem em paralelo\n",
    "models = [\n",
    "    (\"SVM\", SVC(kernel=\"rbf\")),\n",
    "    (\"KNN\", KNeighborsClassifier(n_neighbors=5)),\n",
    "    (\"Random Forest\", RandomForestClassifier(n_estimators=100)),\n",
    "]\n",
    "\n",
    "def train_model_parallel(name, model, X_train_s, y_train_s, X_test, y_test):\n",
    "    # Inicia o cronômetro\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Treina o modelo\n",
    "    model.fit(X_train_s, y_train_s)\n",
    "    \n",
    "    # Para o cronômetro\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "\n",
    "    # Prediz as classes de teste\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calcula a sensibilidade e especificidade do modelo\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    sensitivity = cm[0, 0] / (cm[0, 0] + cm[1, 0])\n",
    "    specificity = cm[1, 1] / (cm[1, 1] + cm[0, 1])\n",
    "    \n",
    "    # Imprime os resultados na tela\n",
    "    print(f\"Resultados para o modelo {name}:\")\n",
    "    print(f\"Tempo de execução (s): {time_taken}\")\n",
    "    print(f\"Sensibilidade (%): {sensitivity * 100}\")\n",
    "    print(f\"Especificidade (%): {specificity * 100}\")\n",
    "    \n",
    "    # Retorna os resultados\n",
    "    return {\n",
    "        \"Modelo\": name,\n",
    "        \"Tempo de execução (s)\": time_taken,\n",
    "        \"Sensibilidade (%)\": sensitivity * 100,\n",
    "        \"Especificidade (%)\": specificity * 100,\n",
    "    }\n",
    "\n",
    "# Modelagem em paralelo\n",
    "results_parallel = Parallel(n_jobs=-1)(\n",
    "    delayed(train_model_parallel)(name, model, X_train_s, y_train_s, X_test, y_test)\n",
    "    for name, model in models\n",
    ")\n",
    "\n",
    "# Convertendo explicitamente o resultado em uma lista\n",
    "results_list = list(results_parallel)\n",
    "\n",
    "# Cria um DataFrame com os resultados\n",
    "decision_matrix_parallel = pd.DataFrame(results_list)\n",
    "\n",
    "# Imprime os resultados\n",
    "print(\"*** Resultados TOPSIS ***\")\n",
    "print(\"Modelo | Posição\")\n",
    "\n",
    "# Definindo criteria objectives\n",
    "minmax = [\"min\", \"max\", \"max\"]\n",
    "\n",
    "# Definindo criteria weights\n",
    "weights = [0.2, 0.6, 0.2]\n",
    "\n",
    "# Normalizando a matriz de decisão\n",
    "norm_decision = decision_matrix_parallel.copy()\n",
    "\n",
    "# Seleciona apenas as colunas numéricas para a normalização\n",
    "numeric_columns = norm_decision.select_dtypes(include=['number']).columns\n",
    "norm_decision[numeric_columns] = norm_decision[numeric_columns].apply(lambda x: x / np.linalg.norm(x), axis=0)\n",
    "\n",
    "# Calculando as distâncias ao ideal positivo e negativo\n",
    "pos_ideal = norm_decision.max(axis=0)\n",
    "neg_ideal = norm_decision.min(axis=0)\n",
    "\n",
    "# Calculando a distância de cada alternativa ao ideal positivo e negativo\n",
    "distance_pos = np.sqrt(np.sum((norm_decision[numeric_columns] - pos_ideal[numeric_columns]) ** 2, axis=1))\n",
    "distance_neg = np.sqrt(np.sum((norm_decision[numeric_columns] - neg_ideal[numeric_columns]) ** 2, axis=1))\n",
    "\n",
    "# Calculando o indicador TOPSIS\n",
    "topsis_scores = distance_neg / (distance_pos + distance_neg)\n",
    "\n",
    "# Classificando as alternativas de acordo com o indicador TOPSIS\n",
    "ranking = topsis_scores.argsort()[::-1]\n",
    "\n",
    "# Imprimindo os resultados\n",
    "print(\"*** Resultados TOPSIS ***\")\n",
    "print(\"Modelo | Posição\")\n",
    "for i in range(len(ranking)):\n",
    "    print(f\"{decision_matrix_parallel.loc[ranking[i], 'Modelo']} | {i + 1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
